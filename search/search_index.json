{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"instructor-js","text":"<p>Structured extraction in Typescript, powered by llms, designed for simplicity, transparency, and control.</p> <p> </p> <p>Dive into the world of Typescript-based structured extraction, by OpenAI's function calling API and Zod, typeScript-first schema validation with static type inference. Instructor stands out for its simplicity, transparency, and user-centric design. Whether you're a seasoned developer or just starting out, you'll find Instructor's approach intuitive and steerable.</p> <p>Check us out in Python, Elixir and PHP.</p> <p>If you want to port Instructor to another language, please reach out to us on Twitter we'd love to help you get started!</p>"},{"location":"#usage","title":"Usage","text":"<p>To check out all the tips and tricks to prompt and extract data, check out the documentation.</p> <pre><code>import Instructor from \"@instructor-ai/instructor\";\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\"\n})\n\nconst UserSchema = z.object({\n  // Description will be used in the prompt\n  age: z.number().describe(\"The age of the user\"), \n  name: z.string()\n})\n\n\n// User will be of type z.infer&lt;typeof UserSchema&gt;\nconst user = await client.chat.completions.create({\n  messages: [{ role: \"user\", content: \"Jason Liu is 30 years old\" }],\n  model: \"gpt-3.5-turbo\",\n  response_model: { \n    schema: UserSchema, \n    name: \"User\"\n  }\n})\n\nconsole.log(user)\n// { age: 30, name: \"Jason Liu\" }\n</code></pre>"},{"location":"#why-use-instructor","title":"Why use Instructor?","text":"<p>The question of using Instructor is fundamentally a question of why to use zod.</p> <ol> <li> <p>Powered by OpenAI \u2014 Instructor is powered by OpenAI's function calling API. This means you can use the same API for both prompting and extraction.</p> </li> <li> <p>Customizable \u2014 Zod is highly customizable. You can define your own validators, custom error messages, and more.</p> </li> <li> <p>Ecosystem Zod is the most widely used data validation library for Typescript.</p> </li> <li> <p>Battle Tested \u2014 Zod is downloaded over 24M times per month, and supported by a large community of contributors.</p> </li> </ol>"},{"location":"#more-examples","title":"More Examples","text":"<p>If you'd like to see more check out our cookbook.</p> <p>Installing Instructor is a breeze. </p>"},{"location":"#contributing","title":"Contributing","text":"<p>If you want to help out, checkout some of the issues marked as <code>good-first-issue</code> or <code>help-wanted</code>. Found here. They could be anything from code improvements, a guest blog post, or a new cook book.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the MIT License.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>We would love for you to contribute to <code>Instructor-js</code>.</p>"},{"location":"contributing/#migrating-docs-from-python","title":"Migrating Docs from Python","text":"<p>Theres a bunch of examples in the python version, including documentation here python docs</p> <p>If you want to contribute, please check out issues</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>If you find a bug, please file an issue on our issue tracker on GitHub.</p> <p>To help us reproduce the bug, please provide a minimal reproducible example, including a code snippet and the full error message.</p> <ol> <li>The <code>response_model</code> you are using.</li> <li>The <code>messages</code> you are using.</li> <li>The <code>model</code> you are using.</li> </ol>"},{"location":"contributing/#contribution-guidelines","title":"Contribution Guidelines","text":"<p>This projectuses Bun &amp; Typescript.</p>"},{"location":"contributing/#environment-setup","title":"Environment Setup","text":""},{"location":"contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Ensure you have the correct versions of all required runtimes/tools. This project uses a <code>.tool-versions</code> file at the root of the repository. If you have asdf (a universal version manager), it should automatically pick up the required versions.</li> </ul>"},{"location":"contributing/#installation","title":"Installation","text":"<ol> <li>Install Dependencies:    Run the following command to install the project dependencies:</li> </ol> <pre><code>bun install\n</code></pre> <ol> <li>Environment Variables: Copy the <code>.example.env</code> file to <code>.env</code> and fill in the necessary values for the OpenAI and Anyscale keys.</li> </ol>"},{"location":"contributing/#code-quality-tools","title":"Code Quality Tools","text":"<ul> <li>This project uses ESLint and Prettier for code formatting and quality checks.</li> <li>Prettier is integrated with ESLint, so it's recommended to use an ESLint plugin in your IDE.</li> <li>For Visual Studio Code or Cursor users: Project-level settings are configured to enable ESLint autosave. </li> </ul> <p>The IDE should prompt you to install recommended plugins.</p> <p>*Note: If using the Prettier plugin, ensure it's disabled to avoid conflicts.</p>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<ul> <li>Execute tests using the following command:</li> </ul> <pre><code>bun test\n</code></pre>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>We welcome pull requests! There is plenty to do, and we are happy to discuss any contributions you would like to make.</p> <p>If it is not a small change, please start by filing an issue first.</p> <p>If you need ideas, you can check out the help wanted or good first issue labels.</p>"},{"location":"contributing/#source-code-changes","title":"Source Code Changes","text":"<ul> <li>If your PR includes changes to the source code, include a <code>changeset</code>.</li> <li>Changesets help manage and automate versioning.</li> <li>Create a changeset by running <code>bun changeset</code> at the root of the project and following the prompts.</li> <li>Be descriptive in the changeset as it will be included in the changelog for the next release.</li> <li>Choose <code>patch</code>, <code>minor</code>, or <code>major</code> for your changeset depending on the type of change.</li> <li>Commit the changeset file (an auto-generated markdown file describing the changes). This will trigger a CI action once merged and stack the change on top of any existing ones in preparation for the next release.</li> </ul> <p>For more information on changesets, visit: Changesets GitHub Repository</p>"},{"location":"contributing/#community-and-support","title":"Community and Support","text":"<ul> <li>Join our community on Discord: Join Discord</li> <li>Reach out on Twitter: @dimitrikennedy @jxnlco</li> </ul>"},{"location":"contributing/#contributors","title":"Contributors","text":""},{"location":"contributing/#additional-resources","title":"Additional Resources","text":"<p>Python is required to run the documentation locally using mkdocs.</p> <p>To enhance your understanding of the documentation, here are some useful references:</p> <ul> <li> <p>mkdocs serve: The <code>mkdocs serve</code> command is used to preview your documentation locally during the development phase. When you run this command in your terminal, MkDocs starts a development server, allowing you to view and interact with your documentation in a web browser. This is helpful for checking how your changes look before publishing the documentation. Learn more in the mkdocs serve documentation.</p> </li> <li> <p>hl_lines in Code Blocks: The <code>hl_lines</code> feature in code blocks allows you to highlight specific lines within the code block. This is useful for drawing attention to particular lines of code when explaining examples or providing instructions. You can specify the lines to highlight using the <code>hl_lines</code> option in your code block configuration. For more details and examples, you can refer to the hl_lines documentation.</p> </li> <li> <p>Admonitions: Admonitions are a way to visually emphasize or call attention to certain pieces of information in your documentation. They come in various styles, such as notes, warnings, tips, etc. Admonitions provide a structured and consistent way to present important content. For usage examples and details on incorporating admonitions into your documentation, you can refer to the admonitions documentation.</p> </li> </ul> <p>For more details about the documentation structure and features, refer to the MkDocs Material documentation.</p> <p>Thank you for your contributions, and happy coding!</p>"},{"location":"guidelines/","title":"Contribution Guidelines","text":"<p>This document outlines the process and guidelines for contributing to this project, which uses Bun &amp; Typescript.</p>"},{"location":"guidelines/#environment-setup","title":"Environment Setup","text":""},{"location":"guidelines/#prerequisites","title":"Prerequisites","text":"<ul> <li>Ensure you have the correct versions of all required runtimes/tools. This project uses a <code>.tool-versions</code> file at the root of the repository. If you have asdf (a universal version manager), it should automatically pick up the required versions.</li> </ul>"},{"location":"guidelines/#installation","title":"Installation","text":"<ol> <li>Install Dependencies:    Run the following command to install the project dependencies:</li> </ol> <pre><code>bun install\n</code></pre> <ol> <li>Environment Variables: Copy the <code>.example.env</code> file to <code>.env</code> and fill in the necessary values for the OpenAI and Anyscale keys.</li> </ol>"},{"location":"guidelines/#code-quality-tools","title":"Code Quality Tools","text":"<ul> <li>This project uses ESLint and Prettier for code formatting and quality checks.</li> <li>Prettier is integrated with ESLint, so it's recommended to use an ESLint plugin in your IDE.</li> <li>For Visual Studio Code or Cursor users: Project-level settings are configured to enable ESLint autosave. </li> </ul> <p>The IDE should prompt you to install recommended plugins.</p> <p>*Note: If using the Prettier plugin, ensure it's disabled to avoid conflicts.</p>"},{"location":"guidelines/#running-tests","title":"Running Tests","text":"<ul> <li>Execute tests using the following command:</li> </ul> <pre><code>bun test\n</code></pre>"},{"location":"guidelines/#making-contributions","title":"Making Contributions","text":""},{"location":"guidelines/#pull-requests-prs","title":"Pull Requests (PRs)","text":"<ul> <li>Keep PRs focused and scoped to specific changes.</li> <li>Provide detailed descriptions in your PRs. Screenshots or videos are excellent ways to enhance communication.</li> </ul>"},{"location":"guidelines/#source-code-changes","title":"Source Code Changes","text":"<ul> <li>If your PR includes changes to the source code, include a <code>changeset</code>.</li> <li>Changesets help manage and automate versioning.</li> <li>Create a changeset by running <code>bun changeset</code> at the root of the project and following the prompts.</li> <li>Be descriptive in the changeset as it will be included in the changelog for the next release.</li> <li>Choose <code>patch</code>, <code>minor</code>, or <code>major</code> for your changeset depending on the type of change.</li> <li>Commit the changeset file (an auto-generated markdown file describing the changes). This will trigger a CI action once merged and stack the change on top of any existing ones in preparation for the next release.</li> </ul> <p>For more information on changesets, visit: Changesets GitHub Repository</p>"},{"location":"guidelines/#community-and-support","title":"Community and Support","text":"<ul> <li>Join our community on Discord: Join Discord</li> <li>Reach out on Twitter: @dimitrikennedy@jxnlco</li> </ul>"},{"location":"help/","title":"Help with Instructor","text":"<p>Page under construction</p> <p>This page is under construction. Please check back later. Consider contributing to this page by opening a PR! </p>"},{"location":"help/#getting-help-with-instructor","title":"Getting help with Instructor","text":"<p>If you need help getting started with Instructor or with advanced usage, the following sources may be useful.</p>"},{"location":"help/#discord","title":"Discord","text":"<p>The Discord is the best place to get help. You can ask questions, get help with debugging, and discuss Instructor with other users.</p>"},{"location":"help/#concepts","title":"Concepts","text":"<p>The concepts section explains the core concepts of Instructor and how to prompt with models.</p>"},{"location":"help/#cookbooks","title":"Cookbooks","text":"<p>The cookbooks are a great place to start. They contain a variety of examples that demonstrate how to use Instructor in different scenarios.</p>"},{"location":"help/#github-discussions","title":"GitHub Discussions","text":"<p>GitHub discussions are useful for asking questions, your question and the answer will help everyone.</p>"},{"location":"help/#github-issues","title":"GitHub Issues","text":"<p>GitHub issues are useful for reporting bugs or requesting new features.</p>"},{"location":"help/#twitter","title":"Twitter","text":"<p>You can also reach out to me on Twitter if you have any questions or ideas.</p>"},{"location":"installation/","title":"Installation","text":"<p>Installation is as simple as:</p> <pre><code>npm install @instructor-ai/instructor openai zod\n</code></pre> <p>Instructor-js has a few dependencies:</p> <ul> <li><code>openai</code>: OpenAI's  TypeScript / JavaScript library.</li> <li><code>zod</code>: TypeScript-first schema validation with static type inference.</li> </ul>"},{"location":"why/","title":"Why use Instructor?","text":"Why use Zod? <p>Its hard to answer the question of why use Instructor without first answering why use Zod.:</p> <ul> <li> <p>Powered by OpenAI \u2014 Instructor is powered by OpenAI's function calling API. This means you can use the same API for both prompting and extraction.</p> </li> <li> <p>Customization \u2014 Zod is highly customizable. You can define your own validators, custom error messages, and more.</p> </li> <li> <p>Ecosystem \u2014 Zod is the most widely used data validation library for Typescript.</p> </li> <li> <p>Battle tested \u2014 Zod is downloaded over 24M times/month and is supported by a large community of contributors. If you're trying to do something with Zod, someone else has probably already done it.</p> </li> </ul> <p>Our <code>Instructor</code> client for the <code>OpenAI</code> class introduces three key enhancements:</p> <ul> <li>Response Mode: Specify a Zod model to streamline data extraction.</li> <li>Max Retries: Set your desired number of retry attempts for requests.</li> <li>Validation Context: Provide a context object for enhanced validator access.   A Glimpse into Instructor's Capabilities</li> </ul> <p>Using Validators</p> <p>Learn more about validators checkout our blog post Good llm validation is just good validation</p> <p>With Instructor, your code becomes more efficient and readable. Here\u2019s a quick peek:</p>"},{"location":"why/#understanding-the-instructor-class","title":"Understanding the <code>Instructor</code> class","text":"<p>Lets go over the <code>Instructor</code> class. And see how we can leverage it to make use of instructor</p>"},{"location":"why/#step-1-patch-the-openai-client","title":"Step 1: Patch the OpenAI client","text":"<p>First, import the required libraries and construct the Instructor class by passing in the OpenAI client. This exposes new functionality with the <code>response_model</code> parameter.</p> <pre><code>import Instructor from \"@instructor-ai/instructor\";\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\n// Create the OpenAI client\nconst oai = new OpenAI({\n    apiKey: process.env.OPENAI_API_KEY ?? undefined,\n    organization: process.env.OPENAI_ORG_ID ?? undefined,\n})\n\n// This enables response_model keyword\n// from client.chat.completions.create\nconst client = Instructor({\n    client: oai,\n    mode: \"FUNCTIONS\"\n})\n</code></pre>"},{"location":"why/#step-2-define-the-zod-model","title":"Step 2: Define the Zod Model","text":"<p>Create a Zod model to define the structure of the data you want to extract. This model will map directly to the information in the prompt.</p> <pre><code>import { z } from \"zod\"\n\nconst UserSchema = z.object({\n    age: z.number(),\n    name: z.string(),\n})\n\ntype User = z.infer&lt;typeof UserSchema&gt;\n</code></pre>"},{"location":"why/#step-3-extract","title":"Step 3: Extract","text":"<p>Use the <code>client.chat.completions.create</code> method to send a prompt and extract the data into the Zod object. The <code>response_model</code> parameter specifies the Zod schema to use for extraction. Its helpful to annotate the variable with the type of the response model, which will help your IDE provide autocomplete and spell check.</p> <pre><code>const user = await client.chat.completions.create({\n    messages: [{ role: \"user\", content: \"Jason Liu is 30 years old\" }],\n    model: \"gpt-3.5-turbo\",\n    response_model: { schema: UserSchema }\n})\n\nconsole.log(user)\n// { age: 30, name: \"Jason Liu\" }\n</code></pre>"},{"location":"why/#understanding-validation","title":"Understanding Validation","text":"<p>This section is a work in progress</p> <p>This section is a work in progress. Consider contributing by opening a PR.</p>"},{"location":"why/#self-correcting-on-validation-error","title":"Self Correcting on Validation Error","text":"<p>Here, the <code>UserDetails</code> Zod schema is passed as the <code>response_model</code>, and <code>max_retries</code> is set to 2.</p> <pre><code>import Instructor from \"@instructor-ai/instructor\";\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst oai = new OpenAI({\n    apiKey: process.env.OPENAI_API_KEY ?? undefined,\n    organization: process.env.OPENAI_ORG_ID ?? undefined,\n})\n\n// Apply the patch to the OpenAI client\nconst client = Instructor({\n    client: oai,\n    mode: \"FUNCTIONS\"\n})\n\n// Use refine to ensure the name is uppercase\nconst UserDetails = z.object({\n    age: z.number(),\n    name: z.string().refine((v) =&gt; v.toUpperCase() === v, {\n        message: \"Name must be in uppercase.\",\n    }\n})\n\nconst user = await client.chat.completions.create({\n    messages: [{ role: \"user\", content: \"Extract jason is 30 years old\" }],\n    model: \"gpt-3.5-turbo\",\n    response_model: { schema: UserDetails },\n    max_retries: 2,\n})\n\nconsole.log(user.name)\n// JASON\n</code></pre> <p>As you can see, we've baked in a self correcting mechanism into the model. This is a powerful way to make your models more robust and less brittle without including a lot of extra code or prompts.</p>"},{"location":"blog/","title":"Welcome to the Instructor Blog","text":"<p>If you wanted to check out the main blog check us out here where we have a bunch of posts about Instructor and OpenAI, and how to think about building with structured prompting. This blog will be more focused on the technical details of the javascript library.</p> <ul> <li>Support for Anyscale's Mistral</li> </ul>"},{"location":"blog/2024/01/01/anyscale/","title":"Structured Outputs with Anyscale and Zod","text":"<p>Open-source LLMS are gaining popularity, and the release of Anyscale's Mistral model has made it possible to obtain structured outputs using JSON schema at any scale. Instead of relying on a model's default output mode, you can utilize JSON schema to obtain structured outputs. This approach is a time-saving alternative to extensive prompt engineering.</p> <p>By the end of this blog post, you will learn how to effectively utilize instructor with Anyscale. But before we proceed, let's first explore the concept of patching.</p>","tags":["patching","open source"]},{"location":"blog/2024/01/01/anyscale/#understanding-modes","title":"Understanding Modes","text":"<p>Instructor's patch enhances a openai api it with the following features, you can learn more about them here, for anyscale they support <code>JSON_SCHEMA</code> and <code>TOOLS</code> modes. and with instructor we'll be able to use the following features:</p> <ul> <li><code>response_model</code> in <code>create</code> calls that returns a Zod schema</li> <li><code>max_retries</code> in <code>create</code> calls that retries the call if it fails by using a backoff strategy</li> </ul>","tags":["patching","open source"]},{"location":"blog/2024/01/01/anyscale/#anyscale","title":"Anyscale","text":"<p>The good news is that Anyscale employs the same OpenAI client, and its models support some of these output modes too!</p> <p>Getting access</p> <p>If you want to try this out for yourself check out the Anyscale website. You can get started here.</p> <p>Let's explore one of the models available in Anyscale's extensive collection!</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst property = z.object({\n  name: z.string(),\n  value: z.string()\n}).describe(\"A property defined by a name and value\")\n\nconst UserSchema = z.object({\n  age: z.number(),\n  name: z.string(),\n  properties: z.array(property)\n})\n\nconst oai = new OpenAI({\n  baseURL: \"https://api.endpoints.anyscale.com/v1\",\n  apiKey: process.env.ANYSCALE_API_KEY ?? undefined,\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"JSON_SCHEMA\"\n})\n\nconst user = await client.chat.completions.create({\n  messages: [{ role: \"user\", content: \"Harry Potter\" }],\n  model: \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n  response_model: { schema: UserSchema },\n  max_retries: 3\n})\n\nconsole.log(user)\n/**\n * {\n  age: 17,\n  name: \"Harry Potter\",\n  properties: [\n    {\n      name: \"House\",\n      value: \"Gryffindor\",\n    }, {\n      name: \"Wand\",\n      value: \"Holly and Phoenix feather\",\n    }\n  ],\n}\n */\n</code></pre> <p>You can find more information about Anyscale's output mode support here.</p>","tags":["patching","open source"]},{"location":"blog/2024/03/07/open-source-local-structured-output-zod-json-openai/","title":"Structured Output for Open Source and Local LLMS","text":"<p>Originally, Instructor facilitated API interactions solely via the OpenAI SDK, with an emphasis on function calling by incorporating Zod for structured data validation and serialization.</p> <p>As the year progressed, we expanded our toolkit by integrating JSON mode, thus enhancing our adaptability to vision models and open source models. This advancement now enables us to support an extensive range of models, from GPT and Mistral to virtually any model accessible through Ollama and Hugging Face. For more insights into leveraging JSON mode with various models, refer back to our detailed guide on Patching.</p>","tags":["llms","opensource","together","llama-cpp-python","anyscale","groq","mistral","ollama"]},{"location":"blog/2024/03/07/open-source-local-structured-output-zod-json-openai/#exploring-different-openai-clients-with-instructor","title":"Exploring Different OpenAI Clients with Instructor","text":"<p>Below, we explore some of the notable clients integrated with Instructor, providing structured outputs and enhanced capabilities, complete with examples of how to initialize and patch each client.</p>","tags":["llms","opensource","together","llama-cpp-python","anyscale","groq","mistral","ollama"]},{"location":"blog/2024/03/07/open-source-local-structured-output-zod-json-openai/#local-models","title":"Local Models","text":"","tags":["llms","opensource","together","llama-cpp-python","anyscale","groq","mistral","ollama"]},{"location":"blog/2024/03/07/open-source-local-structured-output-zod-json-openai/#ollama-a-new-frontier-for-local-models","title":"Ollama: A New Frontier for Local Models","text":"<p>For an in-depth exploration of Ollama, including setup and advanced features, refer to the documentation. The Ollama official website also provides essential resources, model downloads, and community support for newcomers.</p> <pre><code>ollama run llama2\n</code></pre> <pre><code>import Instructor from \"@instructor-ai/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst UserExtractSchema = z.object({\n  age: z.number(),\n  name: z.string()\n})\n\nconst oai = new OpenAI({\n  apiKey: \"ollama\",  // required, but unused\n  baseUrl: \"http://localhost:11434/v1\", // updated API URL\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\"\n})\n\nconst user = await client.chat.completions.create({\n  model: \"llama2\",\n  messages: [{ role: \"user\", content: \"Jason is 30 years old\" }],\n  response_model: { schema: UserExtractSchema, name: \"UserExtractSchema\" }\n})\n\nconsole.log(user)\n// { age: 30, name: \"Jason\" }\n</code></pre>","tags":["llms","opensource","together","llama-cpp-python","anyscale","groq","mistral","ollama"]},{"location":"blog/2024/03/07/open-source-local-structured-output-zod-json-openai/#alternative-providers","title":"Alternative Providers","text":"","tags":["llms","opensource","together","llama-cpp-python","anyscale","groq","mistral","ollama"]},{"location":"blog/2024/03/07/open-source-local-structured-output-zod-json-openai/#anyscale","title":"Anyscale","text":"<pre><code>export ANYSCALE_API_KEY=\"your-api-key\"\n</code></pre> <pre><code>import { z } from \"zod\";\nimport Instructor from \"@instructor-js/instructor\";\nimport OpenAI from \"openai\";\n\n// Define the schema using Zod\nconst UserExtractSchema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n\n// Initialize OpenAI client\nconst oai = new OpenAI({\n  apiKey: process.env.ANYSCALE_API_KEY,\n  base_url: \"https://api.endpoints.anyscale.com/v1\",\n});\n\n// Patch the OpenAI client with Instructor-js\nconst client = Instructor({\n  client: oai,\n  mode: \"JSON_SCHEMA\"\n});\n\n// Use the patched client to create a chat completion\nconst resp = await client.chat.completions.create({\n  model: \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n  messages: [\n    { role: \"system\", content: \"You are a world class extractor\" },\n    { role: \"user\", content: 'Extract the following entities: \"Jason is 20\"' },\n  ],\n  response_model: { schema: UserExtractSchema, name: \"UserExtractSchema\" },\n});\n\nconsole.log(resp);\n// Expected output: { name: 'Jason', age: 20 }\n</code></pre>","tags":["llms","opensource","together","llama-cpp-python","anyscale","groq","mistral","ollama"]},{"location":"blog/2024/03/07/open-source-local-structured-output-zod-json-openai/#groq","title":"Groq","text":"<p>Groq's official documentation, offers a unique approach to processing with its tensor architecture. This innovation significantly enhances the performance of structured output processing.</p> <pre><code>export GROQ_API_KEY=\"your-api-key\"\n</code></pre> <pre><code>import { z } from \"zod\";\nimport Instructor from \"@instructor-js/instructor\";\nimport Groq from \"groq-sdk\";\n\n// Initialize Groq client\nconst groqClient = new Groq({\n  apiKey: process.env.GROQ_API_KEY,\n});\n\n// Define the schema using Zod\nconst UserExtractSchema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n\n// Patch the Groq client with Instructor-js\nconst client = Instructor({\n  client: groqClient,\n  mode: \"FUNCTIONS\",\n});\n\n// Use the patched client to create a chat completion\nconst user = await client.chat.completions.create({\n  model: \"mixtral-8x7b-32768\",\n  response_model: { schema: UserExtractSchema, name: \"UserExtract\" },\n  messages: [\n    { role: \"user\", content: \"Extract jason is 25 years old\" },\n  ],\n});\n\nconsole.log(user);\n// { name: 'jason', age: 25 }\n</code></pre>","tags":["llms","opensource","together","llama-cpp-python","anyscale","groq","mistral","ollama"]},{"location":"blog/2024/03/07/open-source-local-structured-output-zod-json-openai/#together-ai","title":"Together AI","text":"<p>Together AI, when combined with Instructor, offers a seamless experience for developers looking to leverage structured outputs in their applications.</p> <pre><code>export TOGETHER_API_KEY=\"your-api-key\"\n</code></pre> <pre><code>import { z } from \"zod\";\nimport Instructor from \"@instructor-js/instructor\";\nimport OpenAI from \"openai\";\n\n\nconst client = Instructor({\n  client: new OpenAI({\n    apiKey: process.env.TOGETHER_API_KEY,\n    base_url: \"https://api.together.xyz/v1\",\n  }),\n  mode: \"TOOLS\",\n});\n\nconst UserExtractSchema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n\nconst user = await client.chat.completions.create({\n  model: \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n  response_model: { schema: UserExtractSchema, name: \"UserExtract\" },\n  messages: [\n    { role: \"user\", content: \"Extract jason is 25 years old\" },\n  ],\n});\n\nconsole.assert(user instanceof UserExtractSchema, \"Should be instance of UserExtract\");\nconsole.log(user);\n//&gt; name='jason', age=25\n</code></pre>","tags":["llms","opensource","together","llama-cpp-python","anyscale","groq","mistral","ollama"]},{"location":"blog/2024/02/01/together/","title":"Structured Outputs with Together and Zod","text":"<p>Open-source LLMS are gaining popularity, and the release of Togethers's Mistral model has made it possible to obtain structured outputs using JSON schema. Instead of relying on a model's default output mode, you can utilize JSON schema to obtain structured outputs. This approach is a time-saving alternative to extensive prompt engineering.</p> <p>By the end of this blog post, you will learn how to effectively utilize instructor with Togethers. But before we proceed, let's first explore the concept of patching.</p>","tags":["patching","open source"]},{"location":"blog/2024/02/01/together/#understanding-modes","title":"Understanding Modes","text":"<p>Instructor's patch enhances a openai api it with the following features, you can learn more about them here, for Togethers they support <code>JSON_SCHEMA</code> and <code>TOOLS</code> modes. and with instructor we'll be able to use the following features:</p> <ul> <li><code>response_model</code> in <code>create</code> calls that returns a Zod schema</li> <li><code>max_retries</code> in <code>create</code> calls that retries the call if it fails by using a backoff strategy</li> </ul>","tags":["patching","open source"]},{"location":"blog/2024/02/01/together/#anyscale","title":"Anyscale","text":"<p>The good news is that Anyscale employs the same OpenAI client, and its models support some of these output modes too!</p> <p>Getting access</p> <p>If you want to try this out for yourself check out the Together Compute website. You can get started here.</p> <p>Let's explore one of the models available in Together's extensive collection!</p> <pre><code>import Instructor from \"@instructor-ai/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst property = z\n  .object({\n    name: z.string(),\n    value: z.string(),\n  })\n  .describe(\"A property defined by a name and value\");\n\nconst UserSchema = z.object({\n  age: z.number(),\n  name: z.string(),\n  properties: z.array(property),\n})\n\nconst oai = new OpenAI({\n  baseURL: \"https://api.together.xyz\",\n  apiKey: process.env.TOGETHER_API_KEY ?? undefined,\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"JSON_SCHEMA\",\n})\n\nconst user = await client.chat.completions.create({\n  messages: [{ role: \"user\", content: \"Harry Potter\" }],\n  model: \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n  response_model: { schema: UserSchema, name: \"UserSchema\" },\n  max_retries: 3,\n})\n\nconsole.log(user);\n/**\n {\n  age: 17,\n  name: \"Harry Potter\",\n  properties: [\n    {\n      name: \"House\",\n      value: \"Gryffindor\",\n    }, {\n      name: \"Wand\",\n      value: \"Holly and Phoenix feather\",\n    }\n  ],\n}\n **/\n</code></pre> <p>You can find more information about Togethers's output mode support here.</p>","tags":["patching","open source"]},{"location":"concepts/logging/","title":"Logging","text":"<p>In order to see the requests made to OpenAI and the responses, you can set debug to true when initializing Instructor. This will show the requests and responses made to OpenAI. This can be useful for debugging and understanding the requests and responses made to OpenAI.</p> <pre><code>const oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"TOOLS\",\n  debug: true // &lt;== HERE\n})\n\nconst UserSchema = z.object({\n  // Description will be used in the prompt\n  age: z.number().describe(\"The age of the user\"),\n  name: z.string()\n})\n\n// User will be of type z.infer&lt;typeof UserSchema&gt;\nconst user = await client.chat.completions.create({\n  messages: [{ role: \"user\", content: \"Jason Liu is 30 years old\" }],\n  model: \"gpt-3.5-turbo\",\n  response_model: {\n    schema: UserSchema,\n    name: \"User\"\n  }\n})\n// [Instructor:DEBUG] 2024-03-28T13:42:00.178Z: User making completion call with params:  {\n//   messages: [ { role: 'user', content: 'Jason Liu is 30 years old' } ],\n//   model: 'gpt-3.5-turbo',\n//   stream: false,\n//   tool_choice: { type: 'function', function: { name: 'User' } },\n//   tools: [ { type: 'function', function: [Object] } ]\n// }\n// [Instructor:DEBUG] 2024-03-28T13:42:00.846Z: User Completion validation:  { success: true, data: { age: 30, name: 'Jason Liu' } }\n\nconsole.log(user)\n// { age: 30, name: \"Jason Liu\" }\n</code></pre>"},{"location":"concepts/patching/","title":"Patching","text":"<p>Instructor enhances client functionality with three new keywords for backwards compatibility. This allows use of the enhanced client as usual, with structured output benefits.</p> <ul> <li><code>response_model</code>: Defines the response type for <code>chat.completions.create</code>.</li> <li><code>max_retries</code>: Determines retry attempts for failed <code>chat.completions.create</code> validations.</li> </ul> <p>The default mode is <code>instructor.Mode.TOOLS</code> which is the recommended mode for OpenAI clients. This mode is the most stable and is the most recommended for OpenAI clients. The other modes are for other clients and are not recommended for OpenAI clients.</p>"},{"location":"concepts/patching/#tool-calling","title":"Tool Calling","text":"<p>This is the recommended method for OpenAI clients. It is the most stable as functions is being deprecated soon.</p> <pre><code>import Instructor from \"@instructor-ai/instructor\"\nimport OpenAI from \"openai\"\n\nconst client = Instructor({\n  client: new OpenAI({\n    apiKey: process.env.OPENAI_API_KEY ?? undefined,\n    organization: process.env.OPENAI_ORG_ID ?? undefined\n  }),\n  mode: \"TOOLS\"\n})\n</code></pre>"},{"location":"concepts/patching/#function-calling","title":"Function Calling","text":"<p>Note that function calling is soon to be deprecated in favor of TOOL mode for OpenAI. But will still be supported for other clients.</p> <pre><code>import Instructor from \"@instructor-ai/instructor\"\nimport OpenAI from \"openai\"\n\nconst client = Instructor({\n  client: new OpenAI({\n    apiKey: process.env.OPENAI_API_KEY ?? undefined,\n    organization: process.env.OPENAI_ORG_ID ?? undefined\n  }),\n  mode: \"FUNCTIONS\"\n})\n</code></pre>"},{"location":"concepts/patching/#json-mode","title":"JSON Mode","text":"<p>JSON mode uses OpenAI's JSON fromat for responses. by setting <code>response_format={\"type\": \"json_object\"}</code> in the <code>chat.completions.create</code> method.</p> <pre><code>import Instructor from \"@instructor-ai/instructor\"\nimport OpenAI from \"openai\"\n\nconst client = Instructor({\n  client: new OpenAI({\n    apiKey: process.env.OPENAI_API_KEY ?? undefined,\n    organization: process.env.OPENAI_ORG_ID ?? undefined\n  }),\n  mode: \"JSON\"\n})\n</code></pre>"},{"location":"concepts/patching/#json-schema-mode","title":"JSON Schema Mode","text":"<p>JSON Schema mode uses OpenAI's JSON format for responses. by setting <code>response_format={\"type\": \"json_object\", schema:response_model.model_json_schema()}</code> in the <code>chat.completions.create</code> method. This is only available for select clients (e.g. llama-cpp-python, Anyscale, Together)</p> <pre><code>import Instructor from \"@instructor-ai/instructor\"\nimport OpenAI from \"openai\"\n\nconst client = Instructor({\n  client: new OpenAI({\n    apiKey: process.env.OPENAI_API_KEY ?? undefined,\n    organization: process.env.OPENAI_ORG_ID ?? undefined\n  }),\n  mode: \"JSON_SCHEMA\"\n})\n</code></pre>"},{"location":"concepts/patching/#markdown-json-mode","title":"Markdown JSON Mode","text":"<p>This just asks for the response in JSON format, but it is not recommended, and may not be supported in the future, this is just left to support vision models and will not give you the full benefits of instructor.</p> <p>Experimental</p> <p>This is not recommended, and may not be supported in the future, this is just left to support vision models.</p> <pre><code>const client = Instructor({\n  client: new OpenAI({\n    apiKey: process.env.OPENAI_API_KEY ?? undefined,\n    organization: process.env.OPENAI_ORG_ID ?? undefined\n  }),\n  mode: \"MD_JSON\"\n})\n</code></pre>"},{"location":"concepts/philosophy/","title":"Philosophy","text":"<p>The instructor values simplicity and flexibility in leveraging language models (LLMs). It offers a streamlined approach for structured output, avoiding unnecessary dependencies or complex abstractions. Let Zod do the heavy lifting.</p> <p>\u201cSimplicity is a great virtue but it requires hard work to achieve it and education to appreciate it. And to make matters worse: complexity sells better.\u201d \u2014 Edsger Dijkstra</p>"},{"location":"concepts/philosophy/#the-bridge-to-object-oriented-programming","title":"The Bridge to Object-Oriented Programming","text":"<p><code>instructor</code> acts as a bridge converting text-based LLM interactions into a familiar object-oriented format. Its integration with Zod provides type hints, runtime validation, and robust IDE support; love and supported by many in the JS/TS ecosystem. By treating LLMs as callable functions returning typed objects, instructor makes language models backwards compatible with code, making them practical for everyday use while being complex enough for advanced applications.</p>"},{"location":"concepts/philosophy/#the-zen-of-instructor","title":"The zen of <code>instructor</code>","text":"<p>Maintain the flexibility and power of Typescript, without unnecessary constraints.</p> <p>Begin with a function and a return type hint \u2013 simplicity is key. With my experience maintaining a large enterprize framework at my previous job over many years I've learned that the goal of a making a useful framework is minimizing regret, both for the author and hopefully for the user.</p> <ol> <li>Define a Schema <code>const StructuredData = z.object({})</code></li> <li>Define validators and methods on your schema.</li> <li>Encapsulate all your LLM logic into a function <code>function extract(a): StructuredData {}</code></li> <li>Define typed computations against your data with <code>function compute(data: StructuredData) {}</code> or call methods on your schema <code>data.compute()</code></li> </ol> <p>It should be that simple.</p>"},{"location":"concepts/philosophy/#my-goals","title":"My Goals","text":"<p>The goal for the library, documentation, and blog, is to help you be a better Typescript programmer and as a result a better AI engineer.</p> <ul> <li>The library is a result of my desire for simplicity.</li> <li>The library should help maintain simplicity in your codebase.</li> <li>I won't try to write prompts for you,</li> <li>I don't try to create indirections or abstractions that make it hard to debug in the future</li> </ul> <p>Please note that the library is designed to be adaptable and open-ended, allowing you to customize and extend its functionality based on your specific requirements. If you have any further questions or ideas hit me up on twitter</p> <p>Cheers!</p>"},{"location":"concepts/schema/","title":"Zod Schemas","text":"<p>Zod is a TypeScript-first schema declaration and validation library. It is designed to be easy to use with TypeScript and to be a good fit for the language. It is the primary way of prompt engineering, just note that the room of response_model must be <code>z.object</code>.</p>"},{"location":"concepts/schema/#basic-usage","title":"Basic Usage","text":"<pre><code>import { z } from 'zod';\n\nconst schema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n</code></pre>"},{"location":"concepts/schema/#descriptions-are-prompts","title":"Descriptions are Prompts","text":"<p>One of the core things about instructors is that it's able to use these descriptions as part of the prompt. </p> <pre><code>const userDetails = z.object({\n  name: z.string().description('Your full name'),\n  age: z.number(),\n}).description('Fully extracted user detail');\n</code></pre>"},{"location":"concepts/schema/#inferred-types","title":"Inferred Types","text":"<p>We can also generate types using zod schemas.</p> <pre><code>const schema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n\ntype SchemaType = z.infer&lt;typeof schema&gt;;\n</code></pre>"},{"location":"concepts/schema/#default-values","title":"Default Values","text":"<p>In order to help the language model, we can also define defaults for the values.</p> <pre><code>const schema = z.object({\n  name: z.string(),\n  age: z.number().optional(),\n  isStudent: z.boolean().default(false),\n});\n</code></pre>"},{"location":"concepts/schema/#optional-values","title":"Optional Values","text":"<p>We can also define optional values.</p> <pre><code>const schema = z.object({\n  name: z.string(),\n  age: z.number().optional(),\n});\n</code></pre>"},{"location":"concepts/schema/#nested-schemas","title":"Nested Schemas","text":"<p>Powerful schemas can be created by nesting schemas.</p> <pre><code>const schema = z.object({\n  name: z.string(),\n  address: z.object({\n    street: z.string(),\n    city: z.string(),\n  }),\n});\n</code></pre>"},{"location":"concepts/schema/#arrays","title":"Arrays","text":"<p>Arrays can be defined using the <code>z.array</code> method</p> <pre><code>const schema = z.object({\n  name: z.string(),\n  friends: z.array(z.string()),\n});\n</code></pre>"},{"location":"concepts/schema/#enums","title":"Enums","text":"<p>Enums can be defined using the <code>z.enum</code> method</p> <pre><code>const schema = z.object({\n  name: z.string(),\n  role: z.enum(['admin', 'user']),\n});\n</code></pre>"},{"location":"concepts/streaming/","title":"Streaming","text":"<p>A common use case of structured extraction is defining a single schema class and then making another schema to create a list to do multiple extraction By enabling streaming, you can do multiple extractions in a single request, and then iterate over the results as they come in.</p> <p>To see an example of streaming in production checkout this example</p> <p>Important: Changes in Response Behavior with Streaming Enabled</p> <p>Example: Extracting Conference Information</p> <p>The following TypeScript example demonstrates how to use an Async Generator for streaming responses. It includes a schema definition for extraction and iterates over a stream of data to incrementally update and display the extracted information.</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst ExtractionValuesSchema = z.object({\n  users: z\n    .array(\n      z.object({\n        name: z.string(),\n        email: z.string(),\n        twitter: z.string()\n      })\n    )\n    .min(5),\n  date: z.string(),\n  location: z.string(),\n  budget: z.number(),\n  deadline: z.string().min(1)\n})\n\nconst oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"TOOLS\"\n})\n\n\nconst textBlock = `\nIn our recent online meeting, participants from various backgrounds joined to discuss the upcoming tech conference.\nThe names and contact details of the participants were as follows:\n\n- Name: John Doe, Email: johndoe@email.com, Twitter: @TechGuru44\n- Name: Jane Smith, Email: janesmith@email.com, Twitter: @DigitalDiva88\n- Name: Alex Johnson, Email: alexj@email.com, Twitter: @CodeMaster2023\n- Name: Emily Clark, Email: emilyc@email.com, Twitter: @InnovateQueen\n...\n\nDuring the meeting, we agreed on several key points. The conference will be held on March 15th, 2024,\nat the Grand Tech Arena located at 4521 Innovation Drive. Dr. Emily Johnson, a renowned AI researcher, will be our keynote speaker.\n\nThe budget for the event is set at $50,000, covering venue costs, speaker fees, and promotional activities.\nEach participant is expected to contribute an article to the conference blog by February 20th.\n\nA follow-up meeting is scheduled for January 25th at 3 PM GMT to finalize the agenda and confirm the list of speakers.\n`\n\nconst extractionStream = await client.chat.completions.create({\n  messages: [{ role: \"user\", content: textBlock }],\n  model: \"gpt-4o\",\n  response_model: {\n    schema: ExtractionValuesSchema,\n    name: \"value extraction\"\n  },\n  stream: true,\n  seed: 1\n})\n\nfor await (const result of extractionStream) {\n  try {\n    console.clear()\n    console.log(result)\n  } catch (e) {\n    console.log(e)\n    break\n  }\n}\n</code></pre> <p></p> <p>Enabling streaming alters the nature of the response you receive:</p> <p>Response Type: When streaming is enabled, the response becomes an Async Generator. This generator produces incremental updates until the final result is achieved.</p> <p>Handling the Data: As the Async Generator yields results, you can iterate over these incremental updates. It's important to note that the data from each yield is a complete snapshot of the current extraction state and is immediately usable.</p> <p>Final Value: The last value yielded by the generator represents the completed extraction. This value should be used as the final result.</p>"},{"location":"concepts/streaming/#understanding-openai-completion-requests-and-streaming-responses","title":"Understanding OpenAI Completion Requests and Streaming Responses","text":"<p>Server-Sent Events (SSE) and Async Generators</p> <p>OpenAI's completion requests return responses using Server-Sent Events (SSE), a protocol used to push real-time updates from a server to a client. In this context, the Async Generator in our TypeScript example closely mirrors the behavior of SSE. Each yield from the Async Generator corresponds to an update from the server, providing a continuous stream of data until the completion of the request.</p>"},{"location":"concepts/streaming/#streaming-to-the-browser-or-other-clients","title":"Streaming to the Browser or other clients","text":""},{"location":"concepts/streaming/#challenges-of-browser-streaming-with-instructor","title":"Challenges of Browser Streaming with Instructor","text":"<p>Instructor, while powerful for server-side data validation and extraction, presents certain challenges when streaming directly to the browser:</p> <ul> <li> <p>Complexity in Data Transfer: Instructor's focus on full lifecycle validation means that streaming to the browser often involves transferring fully hydrated models. This can lead to larger data chunks, increasing the amount of data transferred.</p> </li> <li> <p>Handling Data Chunks in the UI: When streaming complete objects, there's the added complexity of managing multiple chunks, splitting, diffing, etc. This can make real-time updates in the browser more challenging to implement efficiently.</p> </li> </ul>"},{"location":"concepts/streaming/#utilizing-websockets","title":"Utilizing WebSockets","text":"<ul> <li> <p>WebSocket Streaming: A viable solution for streaming Instructor's data to the browser is through WebSockets. This allows for continuous streaming of the partially hydrated model, enabling immediate use in the UI.</p> </li> <li> <p>Ease of Use: Using WebSockets, developers can stream the entire partially hydrated model to the client, simplifying the process of updating the UI in real time.</p> </li> </ul>"},{"location":"concepts/streaming/#alternatives-in-serverless-environments","title":"Alternatives in Serverless Environments","text":"<ul> <li>Challenges in Serverless: In serverless environments or scenarios where WebSockets may not be feasible, streaming large, fully hydrated models becomes more complicated due to limitations in transferring large data chunks efficiently.</li> </ul>"},{"location":"concepts/streaming/#leveraging-zod-stream-and-stream-hooks","title":"Leveraging zod-stream and stream-hooks","text":"<ul> <li> <p>Integration with zod-stream: Instructor is built on top of <code>zod-stream</code>, a library that handles the streaming aspects provided by Instructor. <code>zod-stream</code> facilitates the construction of structured completions from an API endpoint, streamlining the data handling process, and provides a client for parsing the raw stream and producing the partially hydrated model.</p> </li> <li> <p>Simplifying UI Updates with stream-hooks: For React applications, integrating <code>stream-hooks</code> with <code>zod-stream</code> can significantly simplify building dynamic UIs. <code>stream-hooks</code> manage the streaming connection and data updates efficiently, reducing overhead and complexity in real-time UI interactions.</p> </li> </ul> <p>While Instructor provides robust server-side capabilities, streaming to the browser introduces complexities that can be effectively managed either through the use of WebSockets or <code>zod-stream</code>, and <code>stream-hooks</code>. These tools complement Instructor's server-side strengths, enabling a more streamlined approach to building dynamic, real-time UIs in various environments, including serverless architectures.</p>"},{"location":"examples/","title":"Cookbook","text":"<p>Page under construction</p> <p>This page is under construction. Please check back later. Consider contributing to this page by opening a PR! Theres a bunch of examples in the python version, including documentation here python docs</p> <p>If you want to contribute, please check out issues</p>"},{"location":"examples/#table-of-contents","title":"Table of Contents","text":"<ul> <li>How do I do classification?</li> <li>How are complex queries decomposed into subqueries for a single request?</li> <li>How are action items and dependencies generated from transcripts?</li> <li>How is AI self-assessment implemented with llm_validator?</li> <li>How are exact citations retrieved using regular expressions and smart prompting?</li> <li>How to enable OpenAI's moderation</li> <li>How are search queries segmented through function calling and multi-task definitions?</li> </ul>"},{"location":"examples/action_items/","title":"Example: Extracting Action Items from Meeting Transcripts","text":"<p>In this guide, we'll walk through how to extract action items from meeting transcripts using OpenAI's API. This use case is essential for automating project management tasks, such as task assignment and priority setting.</p> <p>Motivation</p> <p>Significant amount of time is dedicated to meetings, where action items are generated as the actionable outcomes of these discussions. Automating the extraction of action items can save time and guarantee that no critical tasks are overlooked.</p>"},{"location":"examples/action_items/#defining-the-structures","title":"Defining the Structures","text":"<p>We'll model a meeting transcript as a collection of <code>Ticket</code> objects, each representing an action item. Every <code>Ticket</code> can have multiple <code>Subtask</code> objects, representing smaller, manageable pieces of the main task.</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst PrioritySchema = z.enum([\"HIGH\", \"MEDIUM\", \"LOW\"]);\n\nconst SubtaskSchema = z.object({\n  id: z.number(),\n  name: z.string(),\n})\n\nconst TicketSchema = z.object({\n  id: z.number(),\n  name: z.string(),\n  description: z.string(),\n  priority: PrioritySchema,\n  assignees: z.array(z.string()),\n  subtasks: z.array(SubtaskSchema).optional(),\n  dependencies: z.array(z.number()).optional()\n})\n\nconst ActionItemsSchema = z.object({\n  items: z.array(TicketSchema)\n})\n\ntype ActionItems = z.infer&lt;typeof ActionItemsSchema&gt;\n</code></pre>"},{"location":"examples/action_items/#extracting-action-items","title":"Extracting Action Items","text":"<p>To extract action items from a meeting transcript, we use the <code>extractActionItems</code> function. It calls OpenAI's API, processes the text, and returns a set of action items modeled as <code>ActionItems</code>.</p> <pre><code>const oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\",\n})\n\nconst extractActionItems = async (data: string): Promise&lt;ActionItems | undefined&gt; =&gt; {\n  const actionItems: ActionItems = await client.chat.completions.create({\n    messages: [\n      {\n        \"role\": \"system\",\n        \"content\": \"The following is a transcript of a meeting...\",\n      },\n      {\n        \"role\": \"user\",\n        \"content\": `Create the action items for the following transcript: ${data}`,\n      },\n    ],\n    model: \"gpt-4o\",\n    response_model: { schema: ActionItemsSchema },\n    max_tokens: 1000,\n    temperature: 0.0,\n    max_retries: 2,\n  })\n\n  return actionItems || undefined\n}\n</code></pre>"},{"location":"examples/action_items/#evaluation-and-testing","title":"Evaluation and Testing","text":"<p>To test the <code>extractActionItems</code> function, we provide it with a sample transcript, and then print the JSON representation of the extracted action items.</p> <pre><code>const actionItems = await extractActionItems(\n`Alice: Hey team, we have several critical tasks we need to tackle for the upcoming release. First, we need to work on improving the authentication system. It's a top priority.\n\nBob: Got it, Alice. I can take the lead on the authentication improvements. Are there any specific areas you want me to focus on?\n\nAlice: Good question, Bob. We need both a front-end revamp and back-end optimization. So basically, two sub-tasks.\n\nCarol: I can help with the front-end part of the authentication system.\n\nBob: Great, Carol. I'll handle the back-end optimization then.\n\nAlice: Perfect. Now, after the authentication system is improved, we have to integrate it with our new billing system. That's a medium priority task.\n\nCarol: Is the new billing system already in place?\n\nAlice: No, it's actually another task. So it's a dependency for the integration task. Bob, can you also handle the billing system?\n\nBob: Sure, but I'll need to complete the back-end optimization of the authentication system first, so it's dependent on that.\n\nAlice: Understood. Lastly, we also need to update our user documentation to reflect all these changes. It's a low-priority task but still important.\n\nCarol: I can take that on once the front-end changes for the authentication system are done. So, it would be dependent on that.\n\nAlice: Sounds like a plan. Let's get these tasks modeled out and get started.`\n)\n\nconsole.log({ actionItems: JSON.stringify(actionItems) })\n</code></pre>"},{"location":"examples/action_items/#visualizing-the-tasks","title":"Visualizing the tasks","text":"<p>In order to quickly visualize the data we used code interpreter to create a graphviz export of the json version of the ActionItems array.</p> <p></p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": 1,\n      \"name\": \"Improve Authentication System\",\n      \"description\": \"Revamp the front-end and optimize the back-end of the authentication system\",\n      \"priority\": \"High\",\n      \"assignees\": [\"Bob\", \"Carol\"],\n      \"subtasks\": [\n        {\n          \"id\": 2,\n          \"name\": \"Front-end Revamp\"\n        },\n        {\n          \"id\": 3,\n          \"name\": \"Back-end Optimization\"\n        }\n      ],\n      \"dependencies\": []\n    },\n    {\n      \"id\": 4,\n      \"name\": \"Integrate Authentication System with Billing System\",\n      \"description\": \"Integrate the improved authentication system with the new billing system\",\n      \"priority\": \"Medium\",\n      \"assignees\": [\"Bob\"],\n      \"subtasks\": [],\n      \"dependencies\": [1]\n    },\n    {\n      \"id\": 5,\n      \"name\": \"Update User Documentation\",\n      \"description\": \"Update the user documentation to reflect the changes in the authentication system\",\n      \"priority\": \"Low\",\n      \"assignees\": [\"Carol\"],\n      \"subtasks\": [],\n      \"dependencies\": [2]\n    }\n  ]\n}\n</code></pre> <p>In this example, the <code>extractActionItems</code> function successfully identifies and segments the action items, assigning them priorities, assignees, subtasks, and dependencies as discussed in the meeting.</p> <p>By automating this process, you can ensure that important tasks and details are not lost in the sea of meeting minutes, making project management more efficient and effective.</p>"},{"location":"examples/classification/","title":"Text Classification","text":"<p>This tutorial showcases how to implement text classification tasks\u2014specifically, single-label and multi-label classifications\u2014using the OpenAI API.</p> <p>Motivation</p> <p>Text classification is a common problem in many NLP applications, such as spam detection or support ticket categorization. The goal is to provide a systematic way to handle these cases using OpenAI's GPT models.</p>"},{"location":"examples/classification/#single-label-classification","title":"Single-Label Classification","text":""},{"location":"examples/classification/#defining-the-structures","title":"Defining the Structures","text":"<p>For single-label classification, we first define an <code>enum</code> for possible labels and a Zod schema for the output.</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nenum CLASSIFICATION_LABELS {\n  \"SPAM\" = \"SPAM\",\n  \"NOT_SPAM\" = \"NOT_SPAM\"\n}\n\nconst SimpleClassificationSchema = z.object({\n  class_label: z.nativeEnum(CLASSIFICATION_LABELS)\n})\n\ntype SimpleClassification = z.infer&lt;typeof SimpleClassificationSchema&gt;\n</code></pre>"},{"location":"examples/classification/#classifying-text","title":"Classifying Text","text":"<p>The function <code>classify</code> will perform the single-label classification.</p> <pre><code>const oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\"\n})\n\nasync function classify(data: string): Promise&lt;SimpleClassification&gt; {\n  const classification = await client.chat.completions.create({\n    messages: [{ role: \"user\", content: `\"Classify the following text: ${data}` }],\n    model: \"gpt-3.5-turbo\",\n    response_model: { schema: SimpleClassificationSchema },\n    max_retries: 3\n  })\n\n  return classification\n}\n\nconst classification = await classify(\n  \"Hello there I'm a nigerian prince and I want to give you money\"\n)\n\nconsole.log({ classification })\n// { class_label: 'SPAM' }\n</code></pre>"},{"location":"examples/classification/#multi-label-classification","title":"Multi-Label Classification","text":""},{"location":"examples/classification/#defining-the-structures_1","title":"Defining the Structures","text":"<p>For multi-label classification, we introduce a new enum class and a different Zod schema to handle multiple labels.</p> <pre><code>enum MULTI_CLASSIFICATION_LABELS {\n  \"BILLING\" = \"billing\",\n  \"GENERAL_QUERY\" = \"general_query\",\n  \"HARDWARE\" = \"hardware\"\n}\n\nconst MultiClassificationSchema = z.object({\n  predicted_labels: z.array(z.nativeEnum(MULTI_CLASSIFICATION_LABELS))\n})\n\ntype MultiClassification = z.infer&lt;typeof MultiClassificationSchema&gt;\n</code></pre>"},{"location":"examples/classification/#classifying-text_1","title":"Classifying Text","text":"<p>The function <code>multi_classify</code> is responsible for multi-label classification.</p> <pre><code>async function multi_classify(data: string): Promise&lt;MultiClassification&gt; {\n  const classification = await client.chat.completions.create({\n    messages: [{ role: \"user\", content: `\"Classify the following support ticket: ${data}` }],\n    model: \"gpt-3.5-turbo\",\n    response_model: { schema: MultiClassificationSchema },\n    max_retries: 3\n  })\n  return classification \n}\n\nconst classification = await multi_classify(\n  \"My account is locked and I can't access my billing info. Phone is also broken\"\n)\n\nconsole.log({ classification })\n// { predicted_labels: [ 'billing', 'hardware' ] }\n</code></pre>"},{"location":"examples/content_moderation/","title":"OpenAI Moderation","text":""},{"location":"examples/content_moderation/#overview","title":"Overview","text":"<p>This example uses OpenAI's moderation endpoint to check content compliance with OpenAI's usage policies. It can identify and filter harmful content that violates the policies.</p> <p>The model flags content and classifies it into categories including hate, harassment, self-harm, sexual content, and violence. Each category has subcategories for detailed classification.</p> <p>This validator is to be used for monitoring OpenAI API inputs and outputs, other use cases are currently not allowed.</p>"},{"location":"examples/content_moderation/#incorporating-openai-moderation-validation","title":"Incorporating OpenAI moderation validation","text":"<p>The following code defines a schema to validate content using OpenAI's Moderation endpoint. Zod's <code>.superRefine()</code> is used to apply OpenAI's moderation after the compute. This moderation checks if the content complies with OpenAI's usage policies and flags any harmful content. Here's how it works:</p> <ol> <li> <p>Initialize the OpenAI client and extend it with <code>Instructor</code>. This is not strictly necessary for this example, always recommended in order to leverage the full <code>Instructor</code> functionality.</p> </li> <li> <p>Define a Zod schema for our content, then super refine our <code>message</code> field with <code>moderationValidator(client)</code>. This means that after <code>message</code> is computed, it will be passed to <code>moderationValidator()</code> for validation. </p> </li> </ol> <pre><code>import Instructor from \"@/instructor\";\nimport OpenAI from \"openai\";\nimport { z } from \"zod\";\nimport { moderationValidator } from \"@/dsl/validator\"\n\nconst oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined,\n});\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\",\n});\n\nconst Response = z.object({\n  message: z.string().superRefine(moderationValidator(client))\n})\n\ntry {\n  await Response.parseAsync({ message: \"I want to make them suffer the consequences\" })\n} catch (error) {\n  console.log(error)\n}\n// ZodError: [\n//   {\n//     \"code\": \"custom\",\n//     \"message\": \"Moderation error, `I want to make them suffer the consequences` was flagged for violence\",\n//     \"path\": [\n//       \"message\"\n//     ]\n//   }\n// ]\n\ntry {\n  await Response.parseAsync({ message: \"I want to hurt myself.\" })\n} catch (error) {\n  console.log(error)\n}\n//   ZodError: [\n//   {\n//       \"code\": \"custom\",\n//       \"message\": \"Moderation error, `I want to hurt myself.` was flagged for self-harm, self-harm/intent\",\n//       \"path\": [\n//       \"message\"\n//       ]\n//   }\n// ]\n</code></pre>"},{"location":"examples/query_decomposition/","title":"Planning and Executing a Query Plan","text":"<p>This example demonstrates how to use the OpenAI Function Call ChatCompletion model to plan and execute a query plan in a question-answering system. By breaking down a complex question into smaller sub-questions with defined dependencies, the system can systematically gather the necessary information to answer the main question.</p> <p>Motivation</p> <p>The goal of this example is to showcase how query planning can be used to handle complex questions, facilitate iterative information gathering, automate workflows, and optimize processes. By leveraging the OpenAI Function Call model, you can design and execute a structured plan to find answers effectively.</p> <p>Use Cases:</p> <ul> <li>Complex question answering</li> <li>Iterative information gathering</li> <li>Workflow automation</li> <li>Process optimization</li> </ul> <p>With the OpenAI Function Call model, you can customize the planning process and integrate it into your specific application to meet your unique requirements.</p>"},{"location":"examples/query_decomposition/#defining-the-structures","title":"Defining the structures","text":"<p>Let's define the necessary models to represent the query plan and the queries.</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst QueryTypeSchema = z.enum([\"SINGLE\", \"MERGE_MULTIPLE_RESPONSES\"]);\n\nconst QuerySchema = z.object({\n  id: z.number(),\n  question: z.string(),\n  dependencies: z.array(z.number()).optional(),\n  node_type: QueryTypeSchema.default(\"SINGLE\")\n})\n\nconst QueryPlanSchema = z.object({\n  query_graph: z.array(QuerySchema)\n})\n</code></pre>"},{"location":"examples/query_decomposition/#planning-a-query-plan","title":"Planning a Query Plan","text":"<p>Now, let's demonstrate how to plan and execute a query plan using the defined models and the OpenAI API.</p> <pre><code>const oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\",\n})\n\nconst createQueryPlan = async (question: string): Promise&lt;QueryPlan | undefined&gt; =&gt; {\n  const queryPlan: QueryPlan = await client.chat.completions.create({\n    messages: [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a world class query planning algorithm capable of breaking apart questions into its dependency queries such that the answers can be used to inform the parent question. Do not answer the questions, simply provide a correct compute graph with good specific questions to ask and relevant dependencies. Before you call the function, think step-by-step to get a better understanding of the problem.\",\n      },\n      {\n        \"role\": \"user\",\n        \"content\": `Consider: ${question}\\nGenerate the correct query plan.`,\n      },\n    ],\n    model: \"gpt-4o\",\n    response_model: { schema: QueryPlanSchema },\n    max_tokens: 1000,\n    temperature: 0.0,\n    max_retries: 2,\n  })\n\n  return queryPlan || undefined\n}\n\nconst queryPlan = await createQueryPlan(\n  \"What is the difference in populations of Canada and the Jason's home country?\"\n)\n\nconsole.log({ queryPlan: JSON.stringify(queryPlan) })\n</code></pre> <p>No RAG</p> <p>While we build the query plan in this example, we do not propose a method to actually answer the question. You can implement your own answer function that perhaps makes a retrival and calls openai for retrival augmented generation. That step would also make use of function calls but goes beyond the scope of this example.</p> <pre><code>{\n  \"query_graph\": [\n    {\n      \"id\": 1,\n      \"question\": \"What is the population of Canada?\",\n      \"dependencies\": [],\n      \"node_type\": \"SINGLE\"\n    },\n    {\n      \"id\": 2,\n      \"question\": \"What is the name of Jason's home country?\",\n      \"dependencies\": [],\n      \"node_type\": \"SINGLE\"\n    },\n    {\n      \"id\": 3,\n      \"question\": \"What is the population of {country}?\",\n      \"dependencies\": [2],\n      \"node_type\": \"SINGLE\"\n    },\n    {\n      \"id\": 4,\n      \"question\": \"What is the difference in population between Canada and {country}?\",\n      \"dependencies\": [1, 3],\n      \"node_type\": \"MERGE_MULTIPLE_RESPONSES\"\n    }\n  ]\n}\n</code></pre> <p>In the above code, we define a <code>createQueryPlan</code> function that takes a question as input and generates a query plan using the OpenAI API.</p>"},{"location":"examples/query_decomposition/#conclusion","title":"Conclusion","text":"<p>In this example, we demonstrated how to use the OpenAI Function Call <code>ChatCompletion</code> model to plan and execute a query plan using a question-answering system. We defined the necessary structures using Zod and created a query planner function.</p>"},{"location":"examples/segmenting_search/","title":"Segmenting Search Queries","text":"<p>In this example, we will demonstrate how to leverage the <code>MultiTask</code> and <code>enum</code> features of OpenAI Function Call to segment search queries. We will define the necessary schemas using Zod and demonstrate how segment queries into multiple sub queries and execute them in parallel.</p> <p>Motivation</p> <p>Extracting a list of tasks from text is a common use case for leveraging language models. This pattern can be applied to various applications, such as virtual assistants like Siri or Alexa, where understanding user intent and breaking down requests into actionable tasks is crucial. In this example, we will demonstrate how to use OpenAI Function Call to segment search queries and execute them in parallel.</p>"},{"location":"examples/segmenting_search/#structure-of-the-data","title":"Structure of the Data","text":"<p><code>SearchTypeSchema</code> is a Zod schema that defines the structure of a search query object. It has three fields: <code>title</code>, <code>query</code>, and <code>type</code>. The <code>title</code> field is the title of the request, the <code>query</code> field is the query to search for relevant content, and the <code>type</code> field is the type of search. The <code>executeSearch</code> function is used to execute the search query.</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\"\n})\n\nconst SearchTypeSchema = z\n  .enum([\"VIDEO\", \"EMAIL\"])\n  .describe(\"Enumeration representing the types of searchs that can be performed\")\n\nconst SearchSchema = z\n  .object({\n    title: z.string().describe(\"Title of the request\"),\n    query: z.string().describe(\"Query to search fro relevant content\"),\n    type: SearchTypeSchema.describe(\"Type of search\")\n  })\n  .describe(\n    \"Object representing a single search query which contains title, query, and the search type\"\n  )\n\ntype Search = z.infer&lt;typeof SearchSchema&gt;\n\nasync function executeSearch(search: Search) {\n  setTimeout(\n    () =&gt; console.log(`Searching for ${search.title} with ${search.query} using ${search.type}`),\n    1000\n  )\n}\n\nconst MultiSearchSchema = z\n  .object({\n    searches: z.array(SearchSchema).describe(\"List of searches\")\n  })\n  .describe(\"Object representing multiple search queries\")\n\ntype MultiSearch = z.infer&lt;typeof MultiSearchSchema&gt;\n\nasync function executeMultiSearch(multiSearch: MultiSearch) {\n  return Promise.all(\n    multiSearch.searches.map((search: Search) =&gt; {\n      executeSearch(search)\n    })\n  )\n}\n\n/**\n * Convert a string into multiple search queries\n */\nasync function segment(data: string): Promise&lt;MultiSearch&gt; {\n  return await client.chat.completions.create({\n    messages: [\n      {\n        role: \"system\",\n        content: \"You are a helpful assistant.\"\n      },\n      {\n        role: \"user\",\n        content: `Consider the data below:\\n${data} and segment it into multiple search queries`\n      }\n    ],\n    model: \"gpt-4-1106-preview\",\n    response_model: { schema: MultiSearchSchema, name: \"Multi Search\" },\n    max_tokens: 1000,\n    temperature: 0.1\n  })\n}\n\nconst queries = await segment(\n  \"Please send me the video from last week about the investment case study and also documents about your GPDR policy\"\n)\nexecuteMultiSearch(queries)\n\n// &gt;&gt;&gt; Searching for `Video` with query `investment case study` using `SearchType.VIDEO`\n// &gt;&gt;&gt; Searching for `Documents` with query `GPDR policy` using `SearchType.EMAIL`\n</code></pre>"},{"location":"examples/self_correction/","title":"Self-Correction with <code>LLMValidator</code>","text":""},{"location":"examples/self_correction/#introduction","title":"Introduction","text":"<p>This guide demonstrates how to use <code>LLMValidator</code> for implementing self-healing. The objective is to showcase how an instructor can self-correct by using validation errors and helpful error messages.</p>"},{"location":"examples/self_correction/#setup","title":"Setup","text":"<p>Import required modules to create a zod model</p> <pre><code>import { z } from \"zod\"\n</code></pre>"},{"location":"examples/self_correction/#defining-models","title":"Defining Models","text":"<p>Before building validation logic, define a basic Zod model named <code>QuestionAnswer</code>. We'll use this model to generate a response without validation to see the output.</p> <pre><code>const QuestionAnswer = z.object({\n  question: z.string(),\n  answer: z.string()\n})\n</code></pre>"},{"location":"examples/self_correction/#generating-a-response","title":"Generating a Response","text":"<p>Here we coerce the model to generate a response that is objectionable.</p> <pre><code>import { LLMValidator } from \"@/dsl/validator\"\nimport Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\n\nconst openAi = new OpenAI({ apiKey: process.env.OPENAI_API_KEY ?? \"\" })\n\nconst instructor = Instructor({\n  client: openAi,\n  mode: \"TOOLS\"\n})\n\nconst question = \"What is the meaning of life?\"\nconst context = \"According to the devil the meaning of live is to live a life of sin and debauchery.\"\n\nawait instructor.chat.completions.create({\n    model: \"gpt-4o\",\n    max_retries: 0,\n    response_model: { schema: QuestionAnswer, name: \"Question and Answer\" },\n    messages: [\n      {\n        role: \"system\",\n        content:\n          \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\"\n      },\n      {\n        role: \"user\",\n        content: `using the context: ${context}\\n\\nAnswer the following question: ${question}`\n      }\n    ]\n  })\n</code></pre>"},{"location":"examples/self_correction/#output-before-validation","title":"Output Before Validation","text":"<p>While it calls out the objectionable content, it doesn't provide any details on how to correct it.</p> <pre><code>{\n  \"question\": \"What is the meaning of life?\",\n  \"answer\": \"The meaning of life, according to the context, is to live a life of sin and debauchery.\"\n}\n</code></pre>"},{"location":"examples/self_correction/#adding-custom-validation","title":"Adding Custom Validation","text":"<p>By adding a validator to the <code>answer</code> field, we can try to catch the issue and correct it. Lets integrate <code>LLMValidator</code> into the model and see the error message. Its important to note that you can use all of Zod's validators as you would normally which raise a <code>ZodError</code> with a helpful error message as it will be used as part of the self correction prompt.</p> <pre><code>const QuestionAnswer = z.object({\n  question: z.string(),\n  answer: z.string().superRefine(\n    LLMValidator(instructor, statement, {\n      model: \"gpt-4o\"\n    })\n  )\n})\n\ntry {\n  await instructor.chat.completions.create({\n    model: \"gpt-4o\",\n    max_retries: 0,\n    response_model: { schema: QuestionAnswer, name: \"Question and Answer\" },\n    messages: [\n      {\n        role: \"system\",\n        content:\n          \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\"\n      },\n      {\n        role: \"user\",\n        content: `using the context: ${context}\\n\\nAnswer the following question: ${question}`\n      }\n    ]\n  })\n} catch (e as ZodError[]) {\n  console.error(e[0].message)\n}\n</code></pre>"},{"location":"examples/self_correction/#output-after-validation","title":"Output After Validation","text":"<p>Now, we throw validation error that its objectionable and provide a helpful error message.</p> <pre><code>[\n  {\n    \"code\": \"custom\",\n    \"message\": \"The value is promoting a negative lifestyle with sin and debauchery, which is questionable.\",\n    \"path\": [\n      \"answer\"\n    ]\n  }\n]\n</code></pre>"},{"location":"examples/self_correction/#retrying-with-corrections","title":"Retrying with Corrections","text":"<p>By adding the <code>max_retries</code> parameter, we can retry the request with corrections and use the error message to correct the output.</p> <pre><code>try {\n  await instructor.chat.completions.create({\n    model: \"gpt-4o\",\n    max_retries: 2,\n    response_model: { schema: QuestionAnswer, name: \"Question and Answer\" },\n    messages: [\n      {\n        role: \"system\",\n        content:\n          \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\"\n      },\n      {\n        role: \"user\",\n        content: `using the context: ${context}\\n\\nAnswer the following question: ${question}`\n      }\n    ]\n  })\n} catch (e as ZodError[]) {\n  console.error(e[0].message)\n}\n</code></pre>"},{"location":"examples/self_correction/#final-output","title":"Final Output","text":"<p>Now, we get a valid response that is not objectionable!</p> <pre><code>{\n  \"question\": \"What is the meaning of life?\",\n  \"answer\": \"The meaning of life is a subjective and complex question, often explored in religious, philosophical, and moral contexts. Different individuals and cultures have different beliefs and interpretations regarding the purpose and meaning of life.\",\n}\n</code></pre>"},{"location":"examples/validated_citations/","title":"Example: Answering Questions with Validated Citations","text":"<p>For the full code example check out examples/validated_citations/index.ts</p>"},{"location":"examples/validated_citations/#overview","title":"Overview","text":"<p>This example demonstrates how to use Instructor-js with Zod validators to ensure that every statement made by the Language Model (LM) is backed by a direct quote from the provided context, preventing hallucinations and ensuring citation accuracy. It defines TypeScript functions and Zod schemas to encapsulate the information of individual facts and the entire answer.</p>"},{"location":"examples/validated_citations/#data-structures","title":"Data Structures","text":""},{"location":"examples/validated_citations/#the-fact-schema","title":"The <code>Fact</code> Schema","text":"<p>The <code>Fact</code> schema encapsulates a single statement or fact. It contains two properties:</p> <ul> <li><code>fact</code>: A string representing the body of the fact or statement.</li> <li><code>substring_quote</code>: A list of strings. Each string is a direct quote from the context that supports the <code>fact</code>.</li> </ul>"},{"location":"examples/validated_citations/#validation-method-createfactwithcontext","title":"Validation Method: <code>createFactWithContext</code>","text":"<p>This method dynamically creates a Zod schema for Fact with context-dependent validation. It validates the sources (<code>substring_quote</code>) using regex to find the span of each substring quote within the given context. If a span is not found, the quote is removed from the list. <pre><code>import Instructor from \"@/instructor\"\nimport { z } from \"zod\"\n\n\nfunction createFactWithContext(dynamicContext: string) {\n  return z.object({\n    statement: z.string(),\n    substring_quote: z.array(z.string()).transform((quotes) =&gt; {\n      return quotes.flatMap((quote) =&gt; {\n        const spans = getSpans(quote, dynamicContext);\n        return spans.map(span =&gt; dynamicContext.substring(span[0], span[1]));\n      });\n    })\n  });\n}\n\nfunction getSpans(quote: string, context: string): Array&lt;[number, number]&gt; {\n  const matches: any = [];\n  // Example regex search for simplicity; adjust according to your actual implementation\n  const regex = new RegExp(quote, 'g');\n  let match;\n\n  while ((match = regex.exec(context)) !== null) {\n    matches.push([match.index, regex.lastIndex]);\n  }\n  return matches.length &gt; 0 ? matches : [];\n}\n</code></pre></p>"},{"location":"examples/validated_citations/#the-questionanswer-schema","title":"The <code>QuestionAnswer</code> Schema","text":"<p>This schema encapsulates the question and its corresponding answer. It exists to provide a structure for responses from the OpenAI API call. It contains two properties:</p> <ul> <li><code>question</code>: The question asked.</li> <li><code>answer</code>: A list of <code>Fact</code> objects that make up the answer.</li> </ul> <pre><code>const QuestionAnswer = z.object({\n  question: z.string(),\n  answer: z.array(z.object({\n    statement: z.string(),\n    substring_quote: z.array(z.string()), // Basic structure without dynamic context validation\n  }))\n});\ntype QuestionAnswerType = z.infer&lt;typeof QuestionAnswer&gt;\n</code></pre>"},{"location":"examples/validated_citations/#validation-method-createquestionanswerwithcontext","title":"Validation Method: <code>createQuestionAnswerWithContext</code>","text":"<p>This method dynamically generates a Zod schema for QuestionAnswer with context-sensitive validation, ensuring each Fact object in the answer list has at least one valid source. If a <code>Fact</code> object has no valid sources, it is removed from the <code>answer</code> list.</p> <pre><code>function createQuestionAnswerWithContext(dynamicContext: string) {\n  const FactSchemaWithContext = createFactSchemaWithContext(dynamicContext);\n\n  return z.object({\n    question: z.string(),\n    answer: z.array(FactSchemaWithContext).transform((answers) =&gt; {\n      // Filter out any Facts that, after validation, have no valid quotes\n      return answers.filter(fact =&gt; fact.substring_quote.length &gt; 0);\n    })\n  });\n}\n</code></pre>"},{"location":"examples/validated_citations/#function-to-ask-ai-a-question","title":"Function to Ask AI a Question","text":""},{"location":"examples/validated_citations/#the-askai-function","title":"The <code>askAI</code> Function","text":"<p>This function takes a string <code>question</code> and a string <code>context</code> and returns a <code>QuestionAnswer</code> object. It uses the OpenAI API with the dynamic Zod schema for validation.</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\"\n})\n\nasync function askAI(question: string, context: string): Promise&lt;QuestionAnswerType&gt; {\n  const response = await client.chat.completions.create({\n    model: \"gpt-3.5-turbo-0613\",\n    temperature: 0,\n    response_model: { schema: QuestionAnswer, name: \"Question and Answer\" },\n    messages: [\n      { role: \"system\", content: \"You are a world class algorithm to answer questions with correct and exact citations.\" },\n      { role: \"user\", content: context },\n      { role: \"user\", content: `Question: ${question}` },\n    ],\n  });\n  const QuestionAnswerWithContext = createQuestionAnswerWithContext(context);\n  const parsedResponse = QuestionAnswerWithContext.parse(response);\n\n  return parsedResponse;\n}\n</code></pre>"},{"location":"examples/validated_citations/#example","title":"Example","text":"<p>Here's an example of using these classes and functions to ask a question and validate the answer.</p> <pre><code>const question = \"Where did he go to school?\"\nconst context = `My name is Jason Liu, and I grew up in Toronto Canada but I was born in China.\nI went to an arts high school but in university I studied Computational Mathematics and physics.\n  As part of coop I worked at many companies including Stitchfix, Facebook.\n  I also started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.`\n</code></pre> <p>The output would be a <code>QuestionAnswer</code> object containing validated facts and their sources.</p> <pre><code>{\n  question: \"Where did Jason Liu go to school?\",\n  answer: [\n    {\n      statement: \"Jason Liu went to an arts high school.\",\n      substring_quote: [ \"arts high school\" ],\n    }, \n    {\n      statement: \"Jason Liu studied Computational Mathematics and physics in university.\",\n      substring_quote: [ \"Computational Mathematics and physics\" ],\n    }\n  ],\n}\n</code></pre> <p>This ensures that every piece of information in the answer has been validated against the context.</p>"},{"location":"tips/prompting/","title":"General Guidelines for Zod Schema Engineering","text":"<p>When using Zod for schema definition and validation, adhere to principles ensuring clarity, modularity, and flexibility, similar to Pydantic.</p> <ul> <li>Modularity: Construct self-contained schemas for reuse.</li> <li>Self-Description: Describe fields using Zod's <code>.describe()</code> for clarity.</li> <li>Optionality: Utilize <code>z.union</code> with <code>z.undefined()</code> for optional fields.</li> <li>Standardization: Use <code>z.enum</code> for fields with a specific set of values, including a 'Other' option for ambiguity.</li> <li>Dynamic Data: Apply <code>z.record(z.string())</code> for arbitrary properties, with controlled key-value pairs.</li> <li>Entity Relationships: Define relationships through explicit identifiers and relationship fields.</li> <li>Contextual Logic: Add an optional 'chain of thought' field for context.</li> </ul>"},{"location":"tips/prompting/#modular-chain-of-thought","title":"Modular Chain of Thought","text":"<p>Leverage Zod's flexibility for modular 'chain of thought', enhancing data quality.</p> <pre><code>import { z } from 'zod';\n\nconst Role = z.object({\n  chainOfThought: z.string().describe(\"Sequential reasoning to determine the correct title\"),\n  title: z.string(),\n});\n\nconst UserDetail = z.object({\n  age: z.number(),\n  name: z.string(),\n  role: Role,\n});\n</code></pre>"},{"location":"tips/prompting/#utilizing-optional-attributes","title":"Utilizing Optional Attributes","text":"<p>For optional fields, use <code>z.union</code> with <code>z.undefined()</code>.</p> <pre><code>const UserDetail = z.object({\n  age: z.number(),\n  name: z.string(),\n  role: z.string().optional(),\n});\n</code></pre>"},{"location":"tips/prompting/#error-handling-within-schemas","title":"Error Handling Within Schemas","text":"<p>Create a wrapper schema for handling both successful and error states.</p> <pre><code>const MaybeUser = z.object({\n  result: UserDetail.optional(),\n  error: z.boolean(),\n  message: z.string().optional(),\n});\n\n// `MaybeUser` can now encapsulate both a result and an error state.\n</code></pre>"},{"location":"tips/prompting/#simplification-with-dynamic-patterns","title":"Simplification with Dynamic Patterns","text":"<p>Utilize Zod's dynamic schema creation for streamlining error handling.</p> <pre><code>const Maybe = (schema) =&gt; z.object({\n  result: schema.optional(),\n  error: z.boolean(),\n  message: z.string().optional(),\n});\n\nconst MaybeUser = Maybe(UserDetail);\n</code></pre>"},{"location":"tips/prompting/#tips-for-enumerations","title":"Tips for Enumerations","text":"<p>Implement <code>z.enum</code> for standardized fields, including an 'Other' option.</p> <pre><code>const Role = z.enum([\"PRINCIPAL\", \"TEACHER\", \"STUDENT\", \"OTHER\"]);\n\nconst UserDetail = z.object({\n  age: z.number(),\n  name: z.string(),\n  role: Role,\n});\n</code></pre>"},{"location":"tips/prompting/#reiterate-long-instructions","title":"Reiterate Long Instructions","text":"<p>For complex attributes, restate instructions in the field's description.</p> <pre><code>const Role = z.object({\n  instructions: z.string().describe(\"Repeat the rules for determining the title.\"),\n  title: z.string(),\n});\n</code></pre>"},{"location":"tips/prompting/#handling-arbitrary-properties","title":"Handling Arbitrary Properties","text":"<p>Use <code>z.record(z.string())</code> for undefined attributes.</p> <pre><code>const UserDetail = z.object({\n  age: z.number(),\n  name: z.string(),\n  properties: z.record(z.string()).describe(\"Arbitrary key-value pairs\"),\n});\n</code></pre>"},{"location":"tips/prompting/#limiting-list-lengths","title":"Limiting List Lengths","text":"<p>Control list lengths through Zod's array validations.</p> <pre><code>const Property = z.object({\n  key: z.string(),\n  value: z.string(),\n});\n\nconst UserDetail = z.object({\n  age: z.number(),\n  name: z.string(),\n  properties: z.array(Property).max(6).describe(\"Manageable set of properties\"),\n});\n</code></pre>"},{"location":"tips/prompting/#defining-entity-relationships","title":"Defining Entity Relationships","text":"<p>Explicitly define relationships in your schemas, like user friends' IDs.</p> <pre><code>const UserDetail = z.object({\n  id: z.number(),\n  age: z.number(),\n  name: z.string(),\n  friends: z.array(z.number()).describe(\"List of friend IDs, representing user relationships\"),\n});\n</code></pre>"},{"location":"tips/prompting/#reusing-components-in-different-contexts","title":"Reusing Components in Different Contexts","text":"<p>Reuse components in various contexts by defining them separately.</p> <pre><code>const TimeRange = z.object({\n  startTime: z.number().describe(\"Start time in hours.\"),\n  endTime: z.number().describe(\"End time in hours.\"),\n});\n\nconst UserDetail = z.object({\n  id: z.number(),\n  age: z.number(),\n  name: z.string(),\n  workTime: TimeRange,\n  leisureTime: TimeRange,\n});\n</code></pre> <p>These guidelines should streamline and enhance your Zod schema creation and validation processes.</p>"},{"location":"blog/archive/2024/","title":"2024","text":""}]}